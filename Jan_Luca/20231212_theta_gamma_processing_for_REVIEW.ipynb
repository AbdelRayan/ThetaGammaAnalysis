{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb597a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (1.24.4)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (0.3)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (10.0.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (2.31.3)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (1.11.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (2023.8.30)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=21->scikit-image) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\janlu\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49dca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emd in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: sparse in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (0.14.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (3.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (1.11.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (1.3.2)\n",
      "Requirement already satisfied: dcor in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (0.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (6.0.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (1.24.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (2.1.0)\n",
      "Requirement already satisfied: numba>=0.51 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dcor->emd) (0.57.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (4.42.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (1.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (10.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (0.11.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (21.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->emd) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->emd) (2023.3)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba>=0.51->dcor->emd) (0.40.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->emd) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\janlu\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bcc987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pingouin in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (1.3.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (3.7.2)\n",
      "Requirement already satisfied: outdated in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (0.2.2)\n",
      "Requirement already satisfied: pandas-flavor>=0.2.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (0.6.0)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (2.1.0)\n",
      "Requirement already satisfied: statsmodels>=0.13 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (0.14.0)\n",
      "Requirement already satisfied: seaborn>=0.11 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (0.12.2)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (1.11.2)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (1.24.4)\n",
      "Requirement already satisfied: tabulate in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (0.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (4.42.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (10.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (1.4.5)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.0->pingouin) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.0->pingouin) (2023.3)\n",
      "Requirement already satisfied: xarray in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas-flavor>=0.2.0->pingouin) (2023.8.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels>=0.13->pingouin) (0.5.3)\n",
      "Requirement already satisfied: setuptools>=44 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from outdated->pingouin) (58.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from outdated->pingouin) (2.31.0)\n",
      "Requirement already satisfied: littleutils in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from outdated->pingouin) (0.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->pingouin) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->pingouin) (1.3.2)\n",
      "Requirement already satisfied: six in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.13->pingouin) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->outdated->pingouin) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->outdated->pingouin) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->outdated->pingouin) (2.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->outdated->pingouin) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\janlu\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f0409e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from h5py) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\janlu\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c979eb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sails in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (3.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (1.24.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (3.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (1.11.2)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (4.13.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from importlib-metadata<5.0.0->sails) (3.16.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (2.8.2)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (10.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (1.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (4.42.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sails) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sails) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->sails) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\janlu\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install sails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb8f2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emd.sift as sift\n",
    "import emd.spectra as spectra\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "import sails\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "import time\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.stats import zscore, binned_statistic\n",
    "from scipy.ndimage import center_of_mass\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from skimage.feature import peak_local_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e1eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The get_rem_states function takes in an array of sleep states and the sample rate of the data.\n",
    "def get_rem_states(states, sample_rate):\n",
    "    \"\"\"\n",
    "    Extract consecutive REM (Rapid Eye Movement) sleep states and their start\n",
    "    and end times from an array of sleep states.\n",
    "\n",
    "    Parameters:\n",
    "    - states (numpy.ndarray): One-dimensional array of sleep states.\n",
    "    - sample_rate (int): The sample rate of the data.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: An array containing start and end times of consecutive REM\n",
    "    sleep states. Each row represents a pair of start and end times.\n",
    "\n",
    "    Note:\n",
    "    - Sleep states are represented numerically. In this function, REM sleep\n",
    "      states are identified by the value 5 in the 'states' array.\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    import numpy as np\n",
    "\n",
    "    # Example usage:\n",
    "    sleep_states = np.array([1, 2, 5, 5, 5, 3, 2, 5, 5, 4, 1])\n",
    "    sample_rate = 2500  # Example sample rate in Hz\n",
    "    rem_states_times = get_rem_states(sleep_states, sample_rate)\n",
    "    print(rem_states_times)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the sleep states array is one-dimensional.\n",
    "        states = np.squeeze(states)\n",
    "        # Find the indices where the sleep state is equal to 5, indicating REM sleep.\n",
    "        rem_state_indices = np.where(states == 5)[0]\n",
    "        \n",
    "        # Check if there are no REM states. If so, return an empty array.\n",
    "        if len(rem_state_indices) == 0:\n",
    "            return np.array([])\n",
    "        # Calculate the changes between consecutive REM state indices.\n",
    "        rem_state_changes = np.diff(rem_state_indices)\n",
    "        # Find the indices where consecutive REM states are not adjacent.\n",
    "        split_indices = np.where(rem_state_changes != 1)[0] + 1\n",
    "        # Add indices to split consecutive REM states, including the start and end indices.\n",
    "        split_indices = np.concatenate(([0], split_indices, [len(rem_state_indices)]))\n",
    "        # Create an empty array to store start and end times of consecutive REM states.\n",
    "        consecutive_rem_states = np.empty((len(split_indices) - 1, 2))\n",
    "        # Iterate through the split indices to extract start and end times.\n",
    "        for i, (start, end) in enumerate(zip(split_indices, split_indices[1:])):\n",
    "            start = rem_state_indices[start] * int(sample_rate)\n",
    "            end = rem_state_indices[end - 1] * int(sample_rate)\n",
    "            consecutive_rem_states[i] = np.array([start, end])\n",
    "        # Convert the array to a numpy array.\n",
    "        ##consecutive_rem_states = np.array(consecutive_rem_states)\n",
    "        # Create a mask to filter out consecutive REM states with negative duration.\n",
    "        null_states_mask = np.squeeze(np.diff(consecutive_rem_states) > 0)\n",
    "        consecutive_rem_states = consecutive_rem_states[null_states_mask]\n",
    "        # Return the array containing start and end times of consecutive REM states.\n",
    "        return consecutive_rem_states\n",
    "    # Handle the case where an IndexError occurs, typically due to an empty array.\n",
    "    except IndexError as e:\n",
    "        print(f\"An IndexError occurred in get_rem_states: {e}\")\n",
    "        return np.array([])  # or any default value you want\n",
    "\n",
    "\n",
    "# This function computes the Morlet wavelet transform of a given signal.\n",
    "# It uses the SAILS library to perform the wavelet transform.\n",
    "def morlet_wt(x, sample_rate, frequencies=np.arange(1, 200, 1), n=5, mode='complex'):\n",
    "    \"\"\"\n",
    "    Compute the Morlet wavelet transform of a given signal using the SAILS library.\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): The input signal.\n",
    "    - sample_rate (int): The rate at which the signal is sampled.\n",
    "    - frequencies (numpy.ndarray, optional): The array of frequencies at which to compute the transform\n",
    "      (default is from 1 to 200 Hz).\n",
    "    - n (int, optional): The number of cycles in the Morlet wavelet (default is 5).\n",
    "    - mode (str, optional): The mode of the return, whether 'complex', 'power', or 'amplitude'\n",
    "      (default is 'complex').\n",
    "      \n",
    "    Returns:\n",
    "    - numpy.ndarray: The computed Morlet wavelet transform of the input signal.\n",
    "\n",
    "    Note:\n",
    "    - This function relies on the SAILS library to perform the wavelet transform.\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    import numpy as np\n",
    "\n",
    "    # Example usage:\n",
    "    signal = np.sin(2 * np.pi * 10 * np.arange(0, 1, 1/sample_rate))\n",
    "    wt_result = morlet_wt(signal, sample_rate)\n",
    "    print(wt_result)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    wavelet_transform = sails.wavelet.morlet(x, freqs=frequencies, sample_rate=sample_rate, ncycles=n,\n",
    "                                             ret_mode=mode, normalise=None)\n",
    "    # Return the computed wavelet transform.\n",
    "    return wavelet_transform\n",
    "\n",
    "\n",
    "# The tg_split function categorizes frequency values into three groups: sub-theta, theta, and supra-theta.\n",
    "def tg_split(mask_freq, theta_range=(5, 12)):\n",
    "    \"\"\"\n",
    "    Categorize frequency values into three groups: sub-theta, theta, and supra-theta.\n",
    "\n",
    "    Parameters:\n",
    "    - mask_freq (numpy.ndarray): An array of frequency values that you want to categorize.\n",
    "    - theta_range (tuple, optional): A range of frequencies considered as the theta band\n",
    "      (default is (5, 12) Hz).\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing three boolean masks representing sub-theta, theta, and supra-theta categories.\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    import numpy as np\n",
    "\n",
    "    # Example usage:\n",
    "    freq_values = np.array([3, 8, 10, 15, 20])\n",
    "    sub_mask, theta_mask, supra_mask = tg_split(freq_values)\n",
    "    print(\"Sub-theta frequencies:\", freq_values[sub_mask])\n",
    "    print(\"Theta frequencies:\", freq_values[theta_mask])\n",
    "    print(\"Supra-theta frequencies:\", freq_values[supra_mask])\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # Get the lower and upper bounds of the theta range.\n",
    "    lower = np.min(theta_range)\n",
    "    upper = np.max(theta_range)\n",
    "    # Create a boolean mask for frequencies within the theta range.\n",
    "    mask_index = np.logical_and(mask_freq >= lower, mask_freq < upper)\n",
    "    # Create boolean masks for frequencies below and above the theta range.\n",
    "    sub_mask_index = mask_freq < lower\n",
    "    supra_mask_index = mask_freq > upper\n",
    "    # Assign the boolean masks to variables for each category.\n",
    "    sub = sub_mask_index\n",
    "    theta = mask_index\n",
    "    supra = supra_mask_index\n",
    "    # Return the boolean masks for sub-theta, theta, and supra-theta categories.\n",
    "    return sub, theta, supra\n",
    "\n",
    "# This function finds the indices where a signal crosses zero.\n",
    "# x: The input signal.\n",
    "def zero_cross(x):\n",
    "    \"\"\"\n",
    "    Find the indices where a signal crosses zero.\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): The input signal.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: An array containing the indices where the input signal crosses zero.\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    import numpy as np\n",
    "\n",
    "    # Example usage:\n",
    "    signal = np.array([1, -2, 3, -1, 0, 2, -4, 5])\n",
    "    zero_cross_indices = zero_cross(signal)\n",
    "    print(\"Zero-crossing indices:\", zero_cross_indices)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # Identify where the signal goes from positive to non-positive (decay).\n",
    "    decay = np.logical_and((x > 0)[1:], ~(x > 0)[:-1]).nonzero()[0]\n",
    "    # Identify where the signal goes from non-positive to positive (rise).\n",
    "    rise = np.logical_and((x <= 0)[1:], ~(x <= 0)[:-1]).nonzero()[0]\n",
    "    # Combine the indices of rise and decay, then sort them with ascending indices.\n",
    "    zero_xs = np.sort(np.append(rise, decay))\n",
    "    # Return the sorted indices where the signal crosses zero.\n",
    "    return zero_xs\n",
    "\n",
    "# This function identifies the zero crossings, peaks, and troughs in a signal.\n",
    "def extrema(x):\n",
    "    \"\"\"\n",
    "    Identify the zero crossings, peaks, and troughs in a signal.\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): The input signal.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing three arrays - zero-crossing indices, trough indices, and peak indices.\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    import numpy as np\n",
    "\n",
    "    # Example usage:\n",
    "    signal = np.array([1, -2, 3, -1, 0, 2, -4, 5])\n",
    "    zero_crossings, trough_indices, peak_indices = extrema(signal)\n",
    "    print(\"Zero-crossing indices:\", zero_crossings)\n",
    "    print(\"Trough indices:\", trough_indices)\n",
    "    print(\"Peak indices:\", peak_indices)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # Find the indices where the signal crosses zero.\n",
    "    zero_xs = zero_cross(x)\n",
    "    # Initialize empty arrays to store peak and trough indices.\n",
    "    peaks = np.empty((0,)).astype(int)\n",
    "    troughs = np.empty((0,)).astype(int)\n",
    "    # Iterate through pairs of consecutive zero crossings.\n",
    "    for t1, t2 in zip(zero_xs, zero_xs[1:]):\n",
    "        # Find the index of the maximum absolute value in the current segment.\n",
    "        extrema0 = np.argmax(np.abs(x[t1:t2])).astype(int) + t1\n",
    "        # Check if the value at the found index is positive (peak) or non-positive (trough).\n",
    "        if bool(x[extrema0] > 0):\n",
    "            peaks = np.append(peaks, extrema0)\n",
    "        else:\n",
    "            troughs = np.append(troughs, extrema0)\n",
    "    # Return the indices of zero crossings, troughs, and peaks.\n",
    "    return zero_xs, troughs, peaks\n",
    "\n",
    "#The get_cycles_data function generates a nested dictionary containing extracted data and desired metadata of each REM epochs in the input sleep\n",
    "def get_cycles_data(x, rem_states, sample_rate, frequencies, theta_range=(5, 12)):\n",
    "    \"\"\"\n",
    "    Generate a nested dictionary containing extracted data and desired metadata of each REM epochs in the input sleep\n",
    "    signal\n",
    "\n",
    "    Parameters:\n",
    "    x (numpy.ndarray): The input 1D sleep signal.\n",
    "    rem_states (numpy.ndarray): A sleep state vector where 5 represents REM sleep and other values indicate non-REM.\n",
    "    sample_rate (int or float): The sampling rate of the data.\n",
    "    theta_range (tuple, optional): A tuple defining the theta frequency range (lower, upper).\n",
    "            Default is (5, 12).\n",
    "\n",
    "    Returns:\n",
    "    rem_dict: A nested dictionary of extracted signal data and signal source metadata\n",
    "\n",
    "    Notes:\n",
    "    - The dictionary output structure comes out as below:\n",
    "        |----REM 1\n",
    "        |    |----start_end:\n",
    "        |    |----IMFs:\n",
    "        |    |----IMF Frequencies:\n",
    "        |    |----Instantaneous Phases:\n",
    "        |    |----Instantaneous Frequencies:\n",
    "        |    |----Instantaneous Amplitudes:\n",
    "        |    |----Cycles:\n",
    "        |----REM (...)\n",
    "        |    |--------(...)\n",
    "    \"\"\"\n",
    "\n",
    "    # Squeezing dimensions\n",
    "    x = np.squeeze(x)\n",
    "    rem_states = np.squeeze(rem_states)\n",
    "\n",
    "    print(x.shape)\n",
    "    print(rem_states.shape)\n",
    "\n",
    "    # Detect REM periods\n",
    "    consecutive_rem_states = get_rem_states(rem_states, sample_rate).astype(int)\n",
    "\n",
    "    if consecutive_rem_states.ndim == 3:\n",
    "        consecutive_rem_states=np.squeeze(consecutive_rem_states,0)\n",
    "\n",
    "    print(consecutive_rem_states.shape)\n",
    "\n",
    "    # Intiializing variables\n",
    "    wt_spectrum = []\n",
    "    rem_imf = []\n",
    "    rem_mask_freq = []\n",
    "    instantaneous_phase = []\n",
    "    instantaneous_freq = []\n",
    "    instantaneous_amp = []\n",
    "    sub_theta_sig = np.empty((0,))\n",
    "    theta_peak_sig = np.empty((0,))\n",
    "    cycles = np.empty((0, 5))\n",
    "    rem_dict = {}\n",
    "    sub_dict = rem_dict\n",
    "    good_rem = []\n",
    "    count = 0\n",
    "    # Loop through each REM epoch\n",
    "    for i, rem in enumerate(consecutive_rem_states):\n",
    "        start = rem[0]\n",
    "        end = rem[1]+1\n",
    "        signal = x[start:end]\n",
    "\n",
    "        # Extraction of IMFs and IMF Frequencies for current REM epoch\n",
    "        print('Finding Intrinsic Mode Functions')\n",
    "        imf, mask_freq = sift.iterated_mask_sift(signal,\n",
    "                                                 mask_0='zc',\n",
    "                                                 sample_rate=sample_rate,\n",
    "                                                 ret_mask_freq=True)\n",
    "\n",
    "        # Extract Instantaneous Phase, Frequencies and Amplitudes of each IMF for current REM epoch\n",
    "        print('Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF')\n",
    "        IP, IF, IA = spectra.frequency_transform(imf, sample_rate, 'nht')\n",
    "\n",
    "        # Identify sub-theta, theta, and supra-theta frequencies\n",
    "        sub_theta, theta, supra_theta = tg_split(mask_freq, theta_range)\n",
    "\n",
    "        if np.any(theta):\n",
    "            print('Theta frequencies are valid')\n",
    "            count += 1\n",
    "            good_rem.append(i)\n",
    "            sub_dict.setdefault(f'REM {count}', {})\n",
    "        elif not np.any(theta):\n",
    "            print(f'No valid theta frequencies for REM {i}')\n",
    "            continue\n",
    "\n",
    "        print(f'Processing REM {count} ')\n",
    "\n",
    "        # Generate the time-frequency power spectrum\n",
    "        print('Generating time-frequency matrix')\n",
    "        wavelet_transform = morlet_wt(signal, sample_rate, frequencies, mode='amplitude')\n",
    "\n",
    "        # print('Generating time-frequency matrix')\n",
    "        # if wavelet =='theta':\n",
    "        #     wavelet_transform = morlet_wt(np.sum(imf.T[theta], axis=0),\n",
    "        #                                   sample_rate,\n",
    "        #                                   frequencies,\n",
    "        #                                   mode='amplitude')\n",
    "        # elif wavelet == 'gamma':\n",
    "        #     wavelet_transform = morlet_wt(np.sum(imf.T[supra_theta], axis=0),\n",
    "        #                                   sample_rate,\n",
    "        #                                   frequencies,\n",
    "        #                                   mode='amplitude')\n",
    "        # else:\n",
    "        #     wavelet_transform = morlet_wt(signal, sample_rate, frequencies, mode='amplitude')\n",
    "\n",
    "        wt_spectrum.append(wavelet_transform)\n",
    "        rem_imf.append(imf)\n",
    "        rem_mask_freq.append(mask_freq)\n",
    "        instantaneous_phase.append(IP)\n",
    "        instantaneous_freq.append(IF)\n",
    "        instantaneous_amp.append(IA)\n",
    "\n",
    "        # Generate the theta signal to detect cycles\n",
    "        theta_sig = np.sum(imf.T[theta], axis=0)\n",
    "\n",
    "        # Parse the sub-theta signal of all REM periods into one variable to set amplitude threshold\n",
    "        sub_theta_sig = np.append(sub_theta_sig, np.sum(imf.T[sub_theta], axis=0))\n",
    "\n",
    "        # Generate extrema locations and zero crossing on the generated theta signal\n",
    "        zero_x, trough, peak = extrema(np.sum(imf.T[theta], axis=0))\n",
    "        print(f'Number of zero crossings, {zero_x.shape}')\n",
    "\n",
    "        # Create the cycles array for the current REM epoch\n",
    "        zero_x = np.vstack((zero_x[:-2:2], zero_x[1:-1:2], zero_x[2::2])).T\n",
    "\n",
    "        size_adjust = np.min([trough.shape[0], zero_x.shape[0], peak.shape[0]])\n",
    "        zero_x = zero_x[:size_adjust]\n",
    "        cycle = np.empty((size_adjust, 5))\n",
    "        cycle[:, [0, 2, 4]] = zero_x\n",
    "        if trough[0] < peak[0]:\n",
    "            cycle[:, 1] = trough[:zero_x.shape[0]]\n",
    "            cycle[:, 3] = peak[:zero_x.shape[0]]\n",
    "        else:\n",
    "            cycle[:, 3] = trough[:zero_x.shape[0]]\n",
    "            cycle[:, 1] = peak[:zero_x.shape[0]]\n",
    "\n",
    "        broken_cycle = cycle[~np.all(np.diff(cycle, axis=1) > 0, axis=1)]\n",
    "        broken_cycle_mask = np.diff(broken_cycle, axis=1) > 0\n",
    "\n",
    "        adjust_condition = np.all(np.all(broken_cycle_mask[1:] == [True, False, False, True],\n",
    "                                         axis=0) == True)\n",
    "        adjust_loc = np.where(np.all(np.diff(cycle, axis=1) > 0, axis=1) == False)[0][1:-1]\n",
    "\n",
    "        fixed_cycle = broken_cycle[1:-1]\n",
    "        if adjust_condition:\n",
    "            fixed_cycle[:, 1] = cycle[adjust_loc - 1, 1]\n",
    "            fixed_cycle[:, 3] = cycle[adjust_loc + 1, 3]\n",
    "        else:\n",
    "            fixed_cycle[:, 3] = cycle[adjust_loc - 1, 3]\n",
    "            fixed_cycle[:, 1] = cycle[adjust_loc + 1, 1]\n",
    "\n",
    "        cycle = cycle[np.all(np.diff(cycle, axis=1) > 0, axis=1)]\n",
    "        cycle = np.vstack((cycle, fixed_cycle))\n",
    "        if trough[0] < peak[0]:\n",
    "            cycle = np.hstack((cycle[:-1, 1:-1], cycle[1:, :2]))\n",
    "        else:\n",
    "            cycle = np.hstack((cycle[:-1, 3].reshape((-1, 1)), cycle[1:, :-1]))\n",
    "        print(f'Number of cycles, {cycle.shape}')\n",
    "        # Create an array of amplitudes at the peaks\n",
    "        theta_peak_sig = np.append(theta_peak_sig, theta_sig[cycle[:, 2].astype(int)])\n",
    "        cycles = np.vstack((cycles, cycle + start))\n",
    "\n",
    "    # Set the minimum amplitude threshold and discard unsatisfactory theta peaks\n",
    "    min_peak_amp = 2 * sub_theta_sig.std()\n",
    "    peak_mask = theta_peak_sig > min_peak_amp\n",
    "\n",
    "    # Set the frequency threshold and discard and unsatisfactory difference between trough pairs\n",
    "    upper_diff = np.floor(1000 / np.min(theta_range))\n",
    "    lower_diff = np.floor(1000 / np.max(theta_range))\n",
    "    diff_mask = np.logical_and(np.diff(cycles[:, [0, -1]], axis=1) * (1000 / sample_rate) > lower_diff,\n",
    "                               np.diff(cycles[:, [0, -1]], axis=1) * (1000 / sample_rate) <= upper_diff)\n",
    "\n",
    "    # Create a boolean mask that satisfy both the frequency and amplitude threshold criteria\n",
    "    extrema_mask = np.logical_and(np.squeeze(diff_mask), peak_mask)\n",
    "\n",
    "    # Pass the boolean mask on the cycles array to discard any unsatisfactory cycles\n",
    "    cycles = cycles[extrema_mask]\n",
    "\n",
    "    # Place outputs in a nested dictionary\n",
    "    for j, rem in enumerate(rem_dict.values()):\n",
    "        good_rem_states = consecutive_rem_states[good_rem]\n",
    "        rem['start-end'] = good_rem_states[j]\n",
    "        rem['wavelet_transform'] = wt_spectrum[j]\n",
    "        rem['IMFs'] = rem_imf[j]\n",
    "        rem['IMF_Frequencies'] = rem_mask_freq[j]\n",
    "        rem['Instantaneous Phases'] = instantaneous_phase[j]\n",
    "        rem['Instantaneous Frequencies'] = instantaneous_freq[j]\n",
    "        rem['Instantaneous Amplitudes'] = instantaneous_amp[j]\n",
    "        cycles_mask = (cycles > good_rem_states[j, 0]) & (cycles < good_rem_states[j, 1])\n",
    "        cycles_mask = np.all(cycles_mask == True, axis=1)\n",
    "        if cycles[cycles_mask].size == 0:\n",
    "            rem_cycles = np.zeros((1, 5)).astype(int) # Empty Cycles Array (none of the cycles passed our thresholds)\n",
    "        else:\n",
    "            rem_cycles = cycles[cycles_mask].astype(int)\n",
    "        rem['Cycles'] = rem_cycles\n",
    "\n",
    "    return rem_dict\n",
    "\n",
    "def bin_tf_to_fpp(x, power, bin_count):\n",
    "    \"\"\"\n",
    "    Bin the frequency power profile (TF representation) into frequency power profiles (FPP).\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): A 1D or 2D array specifying the frequency ranges for binning.\n",
    "      For a 1D array, it represents the start and end indices of the frequency range.\n",
    "      For a 2D array of size (n, 2), each row represents the start and end indices for each binning range.\n",
    "    - power (numpy.ndarray): The power values in the frequency domain.\n",
    "    - bin_count (int): The number of bins to use for binning the frequency power profile.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: A 2D array representing the binned frequency power profile.\n",
    "      Each row corresponds to the mean power within each bin for the specified frequency range(s).\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the size of x is invalid.\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    import numpy as np\n",
    "\n",
    "    # Example usage:\n",
    "    frequency_ranges = np.array([[5, 10], [15, 20]])  # Define two frequency ranges\n",
    "    power_spectrum = np.random.rand(100, 30)  # Replace with your actual power spectrum\n",
    "    bin_count = 10\n",
    "\n",
    "    # Bin the power spectrum into frequency power profiles\n",
    "    result_fpp = bin_tf_to_fpp(frequency_ranges, power_spectrum, bin_count)\n",
    "    print(result_fpp)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # Check if x is a 1D array (dimensionality of 1)\n",
    "    if x.ndim == 1:  # Handle the case when x is of size (2)\n",
    "        # If yes, create bin ranges using the values in x and specified bin count\n",
    "        bin_ranges = np.arange(x[0], x[1], 1)\n",
    "        # Calculate the mean power within each bin using binned_statistic\n",
    "        fpp = binned_statistic(bin_ranges, power[:, x[0]:x[1]], 'mean', bins=bin_count)[0]\n",
    "        # Add an extra dimension to match the desired output shape (row vector)\n",
    "        fpp = np.expand_dims(fpp, axis=0)  # Add an extra dimension to match the desired output shape\n",
    "    elif x.ndim == 2:  # Handle the case when x is of size (n, 2)\n",
    "        # If yes, initialize an empty list to store results for each row in x\n",
    "        fpp = []\n",
    "        # Iterate through each row in x\n",
    "        for i in range(x.shape[0]):\n",
    "            # Create bin ranges using the values in the current row of x and specified bin count\n",
    "            bin_ranges = np.arange(x[i, 0], x[i, 1], 1)\n",
    "            # Calculate the mean power within each bin using binned_statistic\n",
    "            fpp_row = binned_statistic(bin_ranges, power[:, x[i, 0]:x[i, 1]], 'mean', bins=bin_count)[0]\n",
    "            # Append the result for the current row to the list\n",
    "            fpp.append(fpp_row)\n",
    "        # Convert the list of results to a numpy array\n",
    "        fpp = np.array(fpp)\n",
    "    # If x has an invalid size, raise a ValueError\n",
    "    else:\n",
    "        raise ValueError(\"Invalid size for x\")\n",
    "    # Return the final result (frequency phase power)\n",
    "    return fpp\n",
    "\n",
    "\n",
    "def calculate_cog(frequencies, angles, amplitudes, ratio):\n",
    "    \"\"\"\n",
    "    Calculate the center of gravity (COG) of the frequency and phase distributions.\n",
    "\n",
    "    Parameters:\n",
    "    - frequencies (numpy.ndarray): Array of frequency values.\n",
    "    - angles (numpy.ndarray): Array of phase angles (in degrees).\n",
    "    - amplitudes (numpy.ndarray): Array of amplitude values corresponding to frequencies and angles.\n",
    "    - ratio (float): Threshold ratio for identifying significant amplitudes.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: A 2D array representing the center of gravity (COG) for each dimension.\n",
    "      Each row corresponds to the COG values for a specific dimension (frequency, phase).\n",
    "\n",
    "    Notes:\n",
    "    - The COG is calculated based on the circular mean of angles weighted by significant amplitudes.\n",
    "    - The threshold for significance is determined by comparing amplitudes to the maximum amplitude within a narrow frequency range.\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    import numpy as np\n",
    "\n",
    "    # Example usage:\n",
    "    frequencies = np.arange(1, 10, 1)\n",
    "    angles = np.random.rand(3, 10) * 360  # Replace with your actual phase angles\n",
    "    amplitudes = np.random.rand(3, 10)  # Replace with your actual amplitude values\n",
    "    ratio = 0.5\n",
    "\n",
    "    # Calculate the COG for the given data\n",
    "    cog_result = calculate_cog(frequencies, angles, amplitudes, ratio)\n",
    "    print(cog_result)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # Convert angles to radians\n",
    "    angles = np.deg2rad(angles)\n",
    "    # Initialize an empty array for the center of gravity (COG)\n",
    "    cog = np.empty((0, 2))\n",
    "    # Check if amplitudes have 2 dimensions (2D array)\n",
    "    if amplitudes.ndim == 2:\n",
    "        # Calculate the numerator and denominator for frequency COG\n",
    "        numerator = np.sum(frequencies * np.sum(amplitudes, axis=1))\n",
    "        denominator = np.sum(amplitudes)\n",
    "        # Calculate the frequency COG (cog_f)\n",
    "        cog_f = numerator / denominator\n",
    "        # Calculate floor and ceil indices for frequency COG\n",
    "        floor = np.floor(cog_f).astype(int) - frequencies[0]\n",
    "        ceil = np.ceil(cog_f).astype(int) - frequencies[0]\n",
    "        # Create a new frequency power profile (FPP) with values greater than the threshold ratio\n",
    "        new_fpp = np.where(amplitudes >= np.max(amplitudes[[floor, ceil], :]) * ratio, amplitudes, 0)\n",
    "        # Calculate phase COG using circular mean of angles weighted by FPP\n",
    "        cog_ph = np.rad2deg(pg.circ_mean(angles, w=np.sum(new_fpp, axis=0)))\n",
    "        # Create a 2D array for COG (frequency, phase)\n",
    "        cog = np.array([cog_f, cog_ph])\n",
    "    # Check if amplitudes have 3 dimensions (3D array)\n",
    "    elif amplitudes.ndim == 3:\n",
    "        # Initialize arrays to store indices for amplitude COG calculation\n",
    "        indices_to_subset = np.empty((amplitudes.shape[0], 2)).astype(int)\n",
    "        cog = np.empty((amplitudes.shape[0], 2))\n",
    "        # Calculate numerator and denominator for frequency COG\n",
    "        numerator = np.sum(frequencies * np.sum(amplitudes, axis=2), axis=1)\n",
    "        denominator = np.sum(amplitudes, axis=(1, 2))\n",
    "         # Calculate frequency COG for each dimension\n",
    "        cog_f = (numerator / denominator)\n",
    "        # Vectorize floor and ceil functions for efficient array operations\n",
    "        vectorized_floor = np.vectorize(np.floor)\n",
    "        vectorized_ceil = np.vectorize(np.ceil)\n",
    "        # Set floor and ceil indices for each dimension\n",
    "        indices_to_subset[:, 0] = vectorized_floor(cog_f) - frequencies[0]\n",
    "        indices_to_subset[:, 1] = vectorized_ceil(cog_f) - frequencies[0]\n",
    "        # Calculate max amplitudes for each dimension\n",
    "        max_amps = np.max(amplitudes[np.arange(amplitudes.shape[0])[:, np.newaxis], indices_to_subset, :], axis=(1, 2))\n",
    "        print(max_amps.shape)\n",
    "        # Loop through each dimension and calculate phase COG\n",
    "        for i, max_amp in enumerate(max_amps):\n",
    "            # Create a new FPP for the current dimension with values greater than the threshold ratio\n",
    "            new_fpp = np.where(amplitudes[i] >= max_amp * ratio, amplitudes[i], 0)\n",
    "            # Calculate phase COG using circular mean of angles weighted by FPP\n",
    "            cog[i, 1] = np.rad2deg(pg.circ_mean(angles, w=np.sum(new_fpp, axis=0)))\n",
    "        # Set frequency COG values for each dimension\n",
    "        cog[:, 0] = cog_f\n",
    "    # Return the final COG array\n",
    "    return cog\n",
    "\n",
    "\n",
    "def boxcar_smooth(x, boxcar_window):\n",
    "    \"\"\"\n",
    "    Smooth a 1D or 2D array using a boxcar window.\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): Input array to be smoothed.\n",
    "    - boxcar_window (int or tuple): Size of the boxcar window for smoothing.\n",
    "      For 1D array, an integer representing the window size.\n",
    "      For 2D array, a tuple (t, f) representing window sizes along the time (t) and frequency (f) dimensions.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Smoothed array using the boxcar window.\n",
    "\n",
    "    Notes:\n",
    "    - If the input array is 1D, the boxcar window size is adjusted to be odd.\n",
    "    - If the input array is 2D, separate boxcar windows are created for the time (t) and frequency (f) dimensions.\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    import numpy as np\n",
    "\n",
    "    # Example usage:\n",
    "    signal_1d = np.random.rand(100)  # Replace with your actual 1D signal\n",
    "    window_size_1d = 5\n",
    "    smoothed_1d = boxcar_smooth(signal_1d, window_size_1d)\n",
    "    print(smoothed_1d)\n",
    "\n",
    "    signal_2d = np.random.rand(100, 50)  # Replace with your actual 2D signal\n",
    "    window_size_2d = (5, 3)\n",
    "    smoothed_2d = boxcar_smooth(signal_2d, window_size_2d)\n",
    "    print(smoothed_2d)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # Check if the input array x is 1-dimensional\n",
    "    if x.ndim == 1:\n",
    "        # Check if the boxcar window size is even, and if so, make it odd by adding 1\n",
    "        if boxcar_window % 2 == 0:\n",
    "            boxcar_window += 1\n",
    "        # Create a boxcar window of size boxcar_window for smoothing\n",
    "        window = np.ones((1, boxcar_window)) / boxcar_window\n",
    "        # Perform 1-dimensional convolution to smooth the input array x\n",
    "        x_spectrum = np.convolve(x, window, mode='same')\n",
    "    else:\n",
    "        # Adjust the boxcar window size to be odd for both dimensions\n",
    "        bool_window = np.where(~boxcar_window % 2 == 0, boxcar_window, boxcar_window + 1)\n",
    "        # Create separate boxcar windows for time (t) and frequency (f) dimensions\n",
    "        window_t = np.ones((1, bool_window[0])) / bool_window[0]\n",
    "        window_f = np.ones((1, bool_window[1])) / bool_window[1]\n",
    "        # Perform 2-dimensional convolution first along the time dimension (t)\n",
    "        x_spectrum_t = convolve2d(x, window_t, mode='same')\n",
    "        # Perform 2-dimensional convolution along the frequency dimension (f)\n",
    "        x_spectrum = convolve2d(x_spectrum_t, window_f.T, mode='same')\n",
    "    # Return the smoothed array x_spectrum\n",
    "    return x_spectrum\n",
    "\n",
    "def rem_fpp_gen(rem_dict, x, sample_rate, frequencies, angles, ratio, boxcar_window=None, norm='', fpp_method='',\n",
    "                cog_method=''):\n",
    "    \"\"\"\n",
    "    Generate Frequency-Power-Phase (FPP) plots for each REM epoch in the input dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - rem_dict (dict): Dictionary containing information about REM epochs and cycles.\n",
    "    - x (numpy.ndarray): 1D sleep signal.\n",
    "    - sample_rate (int or float): Sampling rate of the sleep signal.\n",
    "    - frequencies (numpy.ndarray): Array of frequency values.\n",
    "    - angles (numpy.ndarray): Array of phase angles (in degrees).\n",
    "    - ratio (float): Threshold ratio for identifying significant amplitudes.\n",
    "    - boxcar_window (int or None): Size of the boxcar window for smoothing (default is None).\n",
    "    - norm (str): Normalization method for the time-frequency power spectrum (default is '').\n",
    "    - fpp_method (str): Method for generating FPP plots (default is '').\n",
    "    - cog_method (str): Method for calculating the center of gravity (CoG) (default is '').\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary containing FPP plots and CoG information for each REM epoch.\n",
    "\n",
    "    Notes:\n",
    "    - The function processes each REM epoch in the input dictionary, extracting relevant information such as cycles,\n",
    "      time indices, and the sleep signal. It then generates FPP plots based on the time-frequency power spectrum\n",
    "      obtained using the Morlet wavelet. Additional options for smoothing, normalization, FPP generation, and CoG calculation\n",
    "      can be applied based on the specified parameters.\n",
    "\n",
    "    \"\"\"\n",
    "    # Ensure the input array x is 1-dimensional\n",
    "    x = np.squeeze(x)\n",
    "    # Create an empty dictionary to store REM features\n",
    "    cycles_dict = rem_dict\n",
    "    rem_dict = {}\n",
    "    # Create a sub-dictionary to store features for each REM epoch\n",
    "    sub_dict = rem_dict\n",
    "    # Loop through each REM epoch in the input dictionary\n",
    "    for key, value in cycles_dict.items():\n",
    "        print(key)\n",
    "        # Check if the REM epoch has cycle information\n",
    "        if 'Cycles' in value.keys():\n",
    "            # Create a sub-dictionary for the current REM epoch\n",
    "            sub_dict.setdefault(key, {})\n",
    "            # Extract the time indices for the current REM epoch\n",
    "            sub_dict.setdefault(key, {})\n",
    "            # Extract the signal for the current REM epoch\n",
    "            t = value['start-end'].astype(np.int32)\n",
    "            print(t, t[0], t[1])\n",
    "            # Extract the signal for the current REM epoch\n",
    "            sig = x[t[0]:t[1]]\n",
    "            print(sig.shape)\n",
    "            # Generate the time-frequency power spectrum using Morlet wavelet\n",
    "            power = morlet_wt(sig, sample_rate, frequencies, mode='power').astype(np.float32)\n",
    "             # Extract cycle information and adjust indices to match the current REM epoch\n",
    "            cycles = (value['Cycles'][:, [0, -1]] - t[0]).astype(np.int32)\n",
    "            fpp_plots = bin_tf_to_fpp(cycles, power, 19).astype(np.float32)\n",
    "            # Store the FPP plots in the sub-dictionary\n",
    "            sub_dict[key]['FPP_cycles'] = fpp_plots\n",
    "        else:\n",
    "            continue\n",
    "    return rem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ae549c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: E:/Donders/0_rem_test/raw/3_CN\\post_trial5_2017-11-13_14-17-00\\HPC_100_CH15.continuous.mat\n",
      "Loading data from: E:/Donders/0_rem_test/raw/3_CN\\post_trial5_2017-11-13_14-17-00\\post_trial5_2017-11-13_14-17-00-states.mat\n",
      "LFP data shape: (27322112, 1)\n",
      "States data shape: (1, 10928)\n",
      "Processing data...\n",
      "(27322112,)\n",
      "(10928,)\n",
      "(12, 2)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 1 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (3093,)\n",
      "Number of cycles, (1542, 5)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 2 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (1370,)\n",
      "Number of cycles, (683, 5)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 3 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (910,)\n",
      "Number of cycles, (451, 5)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 4 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (2366,)\n",
      "Number of cycles, (1178, 5)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 5 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (2944,)\n",
      "Number of cycles, (1470, 5)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 6 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (1894,)\n",
      "Number of cycles, (945, 5)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 7 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (1082,)\n",
      "Number of cycles, (539, 5)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 8 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (2564,)\n",
      "Number of cycles, (1280, 5)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 9 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (1799,)\n",
      "Number of cycles, (898, 5)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 10 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (1565,)\n",
      "Number of cycles, (781, 5)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 11 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (1477,)\n",
      "Number of cycles, (737, 5)\n",
      "Finding Intrinsic Mode Functions\n",
      "Extracting Instantaneous Phase, Frequencies and Amplitudes of each IMF\n",
      "Theta frequencies are valid\n",
      "Processing REM 12 \n",
      "Generating time-frequency matrix\n",
      "Number of zero crossings, (415,)\n",
      "Number of cycles, (206, 5)\n",
      "Called get_cycles_data\n",
      "Data processing completed.\n",
      "1069.840344429016\n"
     ]
    }
   ],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"\n",
    "    A class for processing and analyzing data.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, output_dir):\n",
    "        \"\"\"\n",
    "        Initializes the DataProcessor with the input data directory and output directory.\n",
    "\n",
    "        Parameters:\n",
    "        - data_dir (str): The directory containing input data.\n",
    "        - output_dir (str): The directory for storing processed output data.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir  # Set the input data directory.\n",
    "        self.output_dir = output_dir  # Set the output data directory.\n",
    "\n",
    "    def load_data(self, subfolder):\n",
    "        \"\"\"\n",
    "        Load LFP (Local Field Potential) and states data from the specified subfolder.\n",
    "\n",
    "        Parameters:\n",
    "        - subfolder (str): The subfolder within the data directory containing the data files.\n",
    "\n",
    "        Returns:\n",
    "        Tuple: A tuple containing LFP data and states data.\n",
    "        \"\"\"\n",
    "        # Generate file paths for LFP and states data using glob.\n",
    "        # Check for the merged HPC file first, otherwise, use the regular HPC file.\n",
    "        merged_hpc_files = glob.glob(os.path.join(self.data_dir, subfolder, '*_HPC_merged.mat'))\n",
    "        hpc_files = glob.glob(os.path.join(self.data_dir, subfolder, '*HPC*.continuous*.mat'))\n",
    "\n",
    "        if merged_hpc_files:\n",
    "            # If there are merged HPC files, use the first one.\n",
    "            lfp_file = merged_hpc_files[0]\n",
    "        elif hpc_files:\n",
    "            # If no merged HPC files found, but regular HPC files exist, use the first one.\n",
    "            lfp_file = hpc_files[0]\n",
    "        else:\n",
    "            # If no HPC files are found, raise a FileNotFoundError.\n",
    "            raise FileNotFoundError(\"No HPC files found in the specified subfolder.\")\n",
    "\n",
    "        # Find the file that matches the pattern '*states*' in the specified subfolder.\n",
    "        states_file = glob.glob(os.path.join(self.data_dir, subfolder, '*states*'))[0]\n",
    "\n",
    "        print(\"Loading data from:\", lfp_file)\n",
    "        print(\"Loading data from:\", states_file)\n",
    "\n",
    "        # Load LFP and states data using scipy's loadmat function.\n",
    "        lfp_data = sio.loadmat(lfp_file)['HPC']  # Load LFP data from the MATLAB file.\n",
    "        states_data = sio.loadmat(states_file)['states']  # Load states data.\n",
    "\n",
    "        print(\"LFP data shape:\", lfp_data.shape)\n",
    "        print(\"States data shape:\", states_data.shape)\n",
    "\n",
    "        # Check data format\n",
    "        if not isinstance(states_data, np.ndarray):\n",
    "            raise ValueError(\"States data should be a NumPy array.\")\n",
    "\n",
    "        # Check data dimensions (adjust as needed)\n",
    "        if states_data.ndim != 2:\n",
    "            raise ValueError(\"States data should be a 2D array.\")\n",
    "\n",
    "        # Check data range\n",
    "        min_value = np.min(states_data)\n",
    "        max_value = np.max(states_data)\n",
    "        expected_min = 0  # Adjust as needed\n",
    "        expected_max = 5  # Adjust as needed\n",
    "        if min_value < expected_min or max_value > expected_max:\n",
    "            raise ValueError(\"States data range is outside of expected bounds.\")\n",
    "\n",
    "        # Check for missing values\n",
    "        if np.isnan(states_data).any():\n",
    "            raise ValueError(\"States data contains NaN values.\")\n",
    "\n",
    "        return lfp_data, states_data \n",
    "     \n",
    "\n",
    "    def process_data(self, lfp_data, states_data):\n",
    "        \"\"\"\n",
    "        Process LFP (Local Field Potential) and states data.\n",
    "\n",
    "        Parameters:\n",
    "        - lfp_data (numpy.ndarray): The LFP data to be processed.\n",
    "        - states_data (numpy.ndarray): The states data corresponding to the LFP data.\n",
    "\n",
    "        Returns:\n",
    "        dict: A dictionary containing processed data.\n",
    "        \"\"\"\n",
    "        print(\"Processing data...\")\n",
    "        # Define a frequency range for processing.If you also want from 15Hz, replace the 20 with 15!!\n",
    "        frequency_range=np.arange(20,140,1)\n",
    "        # Call a function (get_cycles_data) to process cycles data.\n",
    "        rem_dict = get_cycles_data(lfp_data, states_data, 2500, frequency_range, (5, 12))\n",
    "        print(\"Called get_cycles_data\")\n",
    "        for key, value in rem_dict.items():\n",
    "            # Loop through each key-value pair in rem_dict.\n",
    "            if isinstance(value, (int, float)):\n",
    "                # Check if the value associated with the key is an int or float.\n",
    "                rem_dict[key] = np.float32(value)  # Convert numerical values to np.float32\n",
    "        # Print a message indicating that data processing is completed.\n",
    "        print(\"Data processing completed.\")\n",
    "        # Return the processed rem_dict.\n",
    "        return rem_dict\n",
    "\n",
    "    \n",
    "    def save_data(self, subfolder, rem_dict):\n",
    "        \"\"\"\n",
    "        Save processed data to a file.\n",
    "\n",
    "        Parameters:\n",
    "        - subfolder (str): The subfolder within the output directory for saving data.\n",
    "        - rem_dict (dict): The processed data dictionary to be saved.\n",
    "        \"\"\"\n",
    "        # Create an output subfolder if it doesn't exist.\n",
    "        output_subfolder = os.path.join(self.output_dir, subfolder)\n",
    "        # Create a new folder in the output directory to store the processed data.\n",
    "        os.makedirs(output_subfolder, exist_ok=True)\n",
    "        # Define the output file paths based on the subfolder name.\n",
    "        rem_dict_filename = f\"{subfolder}_REM_dict.h5\"\n",
    "        # Create the full file path for saving the processed data dictionary.\n",
    "        rem_dict_file = os.path.join(output_subfolder, rem_dict_filename)\n",
    "\n",
    "        # Create a function to save a dictionary as an HDF5 group\n",
    "        def save_dict_as_hdf5_group(hdf_group, data_dict):\n",
    "            \"\"\"\n",
    "            Recursively saves a dictionary as an HDF5 group.\n",
    "\n",
    "            Parameters:\n",
    "            - hdf_group (h5py.Group): The HDF5 group to which the dictionary will be saved.\n",
    "            - data_dict (dict): The dictionary to be saved.\n",
    "            \"\"\"\n",
    "            \n",
    "            for key, value in data_dict.items():\n",
    "                # Loop through each key-value pair in the dictionary.\n",
    "                if isinstance(value, dict):\n",
    "                    # If the value is another dictionary, create a subgroup in the HDF5 group.\n",
    "                    subgroup = hdf_group.create_group(key)\n",
    "                    # Create a subgroup within the HDF5 group.\n",
    "                    save_dict_as_hdf5_group(subgroup, value)\n",
    "                else:\n",
    "                    # Otherwise, save the value to the HDF5 group\n",
    "                    hdf_group[key] = value\n",
    "\n",
    "        # Save the rem_dict dictionary as an HDF5 file.\n",
    "        with h5py.File(rem_dict_file, 'w') as hdf_file:\n",
    "            # Use the subfolder name as the top-level group name\n",
    "            subfolder_group = hdf_file.create_group(subfolder)\n",
    "\n",
    "            # Call the function to save rem_dict within the subfolder group\n",
    "            save_dict_as_hdf5_group(subfolder_group, rem_dict)\n",
    "\n",
    "    def process_subfolder_with_timing(self, subfolder):\n",
    "        \"\"\"\n",
    "        Process a subfolder's data with timing information.\n",
    "\n",
    "        Parameters:\n",
    "        - subfolder (str): The subfolder within the data directory to process.\n",
    "\n",
    "        Returns:\n",
    "        - dict: The processed data dictionary (rem_dict).\n",
    "        \"\"\"\n",
    "        start_time = time.time()  # Start measuring time\n",
    "        # Load LFP (Local Field Potential) and states data from the specified subfolder.\n",
    "        lfp_data, states_data = self.load_data(subfolder)\n",
    "        # Process the loaded data and obtain the rem_dict (processed data dictionary).\n",
    "        rem_dict = self.process_data(lfp_data, states_data)  # Process and get the rem_dict\n",
    "        # Save the processed data dictionary to the output directory.\n",
    "        self.save_data(subfolder, rem_dict)  # Save the rem_dict\n",
    "        end_time = time.time()  # Stop measuring time\n",
    "        elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "        print(elapsed_time)  # Print the elapsed time in seconds\n",
    "        # Return the processed data dictionary (rem_dict).\n",
    "        return rem_dict\n",
    "\n",
    "\n",
    "\n",
    "# Specify the input data directory and output directory.\n",
    "data_dir = \"E:/Donders/0_rem_test/raw/3_CN\"  # Replace with your actual data directory path.\n",
    "output_dir = \"E:/Donders/0_rem_test/processed/3_CN\"  # Replace with your desired output directory path.\n",
    "\n",
    "# DataProcessor object.\n",
    "processor = DataProcessor(data_dir, output_dir)\n",
    "\n",
    "# Process all data in the specified directories using parallel processing.\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    \"\"\"\n",
    "    This code concurrently processes data from multiple subfolders using a concurrent.futures.ProcessPoolExecutor. \n",
    "    \n",
    "    It starts by creating the executor, then generates a list of subfolders in the specified data directory.\n",
    "    \n",
    "    In a parallel loop, it calls the process_subfolder_with_timing method of a DataProcessor object for each subfolder, \n",
    "    collecting the processed data dictionaries in the processed_data list. The result is a list containing the \n",
    "    dictionaries for each subfolder after parallel processing.\n",
    "    \"\"\"\n",
    "    # Get a list of subfolders within the specified data directory.\n",
    "    subfolders = [subfolder for subfolder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, subfolder))]\n",
    "    # Create a list to collect processed data dictionaries for each subfolder.\n",
    "    processed_data = []  # Create a list to collect processed data\n",
    "    # Iterate over each subfolder for parallel processing.\n",
    "    for subfolder in subfolders:\n",
    "        # Call the 'process_subfolder_with_timing' method on the DataProcessor object for each subfolder.\n",
    "        result = processor.process_subfolder_with_timing(subfolder)  # Call the method and collect the dictionaries\n",
    "        # Append the processed data dictionary to the list.\n",
    "        processed_data.append(result)  # Append the dictionaries to the list\n",
    "\n",
    "# Now, 'processed_data' contains the dictionaries for each subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96d4d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
