{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb597a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (1.24.4)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (0.3)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (2.31.3)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (2023.8.30)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (1.11.2)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (10.0.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=21->scikit-image) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\janlu\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49dca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emd in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: dcor in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (0.6)\n",
      "Requirement already satisfied: sparse in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (0.14.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (3.7.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (2.1.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (1.11.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (1.24.4)\n",
      "Requirement already satisfied: tabulate in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from emd) (0.9.0)\n",
      "Requirement already satisfied: numba>=0.51 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dcor->emd) (0.57.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (10.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (4.42.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->emd) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->emd) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->emd) (2023.3)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba>=0.51->dcor->emd) (0.40.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->emd) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\janlu\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bcc987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pingouin in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (1.11.2)\n",
      "Requirement already satisfied: pandas-flavor>=0.2.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (0.6.0)\n",
      "Requirement already satisfied: outdated in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (0.2.2)\n",
      "Requirement already satisfied: statsmodels>=0.13 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (0.14.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (3.7.2)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (2.1.0)\n",
      "Requirement already satisfied: seaborn>=0.11 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (0.12.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (21.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (1.1.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (10.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (0.11.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (3.0.9)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.0->pingouin) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.0->pingouin) (2023.3)\n",
      "Requirement already satisfied: xarray in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas-flavor>=0.2.0->pingouin) (2023.8.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels>=0.13->pingouin) (0.5.3)\n",
      "Requirement already satisfied: littleutils in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from outdated->pingouin) (0.2.2)\n",
      "Requirement already satisfied: setuptools>=44 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from outdated->pingouin) (58.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from outdated->pingouin) (2.31.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->pingouin) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->pingouin) (3.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.13->pingouin) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->outdated->pingouin) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->outdated->pingouin) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->outdated->pingouin) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->outdated->pingouin) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\janlu\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f0409e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from h5py) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\janlu\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c979eb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sails in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (4.13.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (1.11.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (3.9.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sails) (3.7.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from importlib-metadata<5.0.0->sails) (3.16.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (1.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->sails) (1.4.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sails) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sails) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\janlu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->sails) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\janlu\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install sails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8f2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emd.sift as sift\n",
    "import emd.spectra as spectra\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "import sails\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "import time\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.stats import zscore, binned_statistic\n",
    "from scipy.ndimage import center_of_mass\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from skimage.feature import peak_local_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e1eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rem_states(states_data, sample_rate):\n",
    "    states_data = np.squeeze(states_data)\n",
    "    rem_state_indices = np.where(states_data == 5)[0]\n",
    "    rem_state_changes = np.diff(rem_state_indices)\n",
    "    split_indices = np.where(rem_state_changes != 1)[0] + 1\n",
    "    split_indices = np.concatenate(([0], split_indices, [len(rem_state_indices)]))\n",
    "    consecutive_rem_states = np.empty((len(split_indices) - 1, 2))\n",
    "    for i, (start, end) in enumerate(zip(split_indices, split_indices[1:])):\n",
    "        start = rem_state_indices[start] * int(sample_rate)\n",
    "        end = rem_state_indices[end - 1] * int(sample_rate)\n",
    "        consecutive_rem_states[i] = np.array([start, end])\n",
    "    consecutive_rem_states = np.array(consecutive_rem_states)\n",
    "    null_states_mask = np.squeeze(np.diff(consecutive_rem_states) > 0)\n",
    "    consecutive_rem_states = consecutive_rem_states[null_states_mask]\n",
    "    return consecutive_rem_states\n",
    "\n",
    "\n",
    "def morlet_wt(x, sample_rate, frequencies=np.arange(1, 200, 1), n=5, mode='complex'):\n",
    "    wavelet_transform = sails.wavelet.morlet(x, freqs=frequencies, sample_rate=sample_rate, ncycles=n,\n",
    "                                             ret_mode=mode, normalise=None)\n",
    "    return wavelet_transform\n",
    "\n",
    "\n",
    "def tg_split(mask_freq, theta_range=(5, 12)):\n",
    "    lower = np.min(theta_range)\n",
    "    upper = np.max(theta_range)\n",
    "    mask_index = np.logical_and(mask_freq >= lower, mask_freq < upper)\n",
    "    sub_mask_index = mask_freq < lower\n",
    "    supra_mask_index = mask_freq > upper\n",
    "    sub = sub_mask_index\n",
    "    theta = mask_index\n",
    "    supra = supra_mask_index\n",
    "\n",
    "    return sub, theta, supra\n",
    "\n",
    "\n",
    "def zero_cross(x):\n",
    "    decay = np.logical_and((x > 0)[1:], ~(x > 0)[:-1]).nonzero()[0]\n",
    "    rise = np.logical_and((x <= 0)[1:], ~(x <= 0)[:-1]).nonzero()[0]\n",
    "    zero_xs = np.sort(np.append(rise, decay))\n",
    "    return zero_xs\n",
    "\n",
    "\n",
    "def extrema(x):\n",
    "    zero_xs = zero_cross(x)\n",
    "    peaks = np.empty((0,)).astype(int)\n",
    "    troughs = np.empty((0,)).astype(int)\n",
    "    for t1, t2 in zip(zero_xs, zero_xs[1:]):\n",
    "        extrema0 = np.argmax(np.abs(x[t1:t2])).astype(int) + t1\n",
    "        if bool(x[extrema0] > 0):\n",
    "            peaks = np.append(peaks, extrema0)\n",
    "        else:\n",
    "            troughs = np.append(troughs, extrema0)\n",
    "    return zero_xs, troughs, peaks\n",
    "\n",
    "\n",
    "def get_cycles_data(x, rem_states, sample_rate, theta_range=(5, 12)):\n",
    "    consecutive_rem_states = get_rem_states(rem_states, sample_rate)\n",
    "    rem_imf = []\n",
    "    rem_mask_freq = []\n",
    "    instantaneous_phase = []\n",
    "    instantaneous_freq = []\n",
    "    instantaneous_amp = []\n",
    "    sub_theta_sig = np.empty((0,), dtype=np.float32)  # Specify dtype here\n",
    "    theta_peak_sig = np.empty((0,), dtype=np.float32)  # Specify dtype here\n",
    "    cycles = np.empty((0, 5), dtype=np.int32)  # Specify dtype here\n",
    "    rem_dict = {}\n",
    "    sub_dict = rem_dict\n",
    "\n",
    "    for i, rem in enumerate(consecutive_rem_states, start=1):\n",
    "        sub_dict.setdefault(f'REM {i}', {})\n",
    "        start = int(rem[0])\n",
    "        end = int(rem[1])\n",
    "        signal = x[start:end]\n",
    "        imf, mask_freq = sift.iterated_mask_sift(signal,\n",
    "                                                 mask_0='zc',\n",
    "                                                 sample_rate=sample_rate,\n",
    "                                                 ret_mask_freq=True)\n",
    "        IP, IF, IA = spectra.frequency_transform(imf, sample_rate, 'nht')\n",
    "        sub_theta, theta, _ = tg_split(mask_freq, theta_range)\n",
    "\n",
    "        rem_imf.append(imf)\n",
    "        rem_mask_freq.append(mask_freq)\n",
    "        instantaneous_phase.append(IP)\n",
    "        instantaneous_freq.append(IF)\n",
    "        instantaneous_amp.append(IA)\n",
    "\n",
    "        theta_sig = np.sum(imf.T[theta], axis=0)\n",
    "        sub_theta_sig = np.append(sub_theta_sig, np.sum(imf.T[sub_theta], axis=0))\n",
    "\n",
    "        zero_x, trough, peak = extrema(np.sum(imf.T[theta], axis=0))\n",
    "\n",
    "        zero_x = np.vstack((zero_x[:-2:2], zero_x[1:-1:2], zero_x[2::2])).T\n",
    "\n",
    "        size_adjust = np.min([trough.shape[0], zero_x.shape[0], peak.shape[0]])\n",
    "        zero_x = zero_x[:size_adjust]\n",
    "        cycle = np.empty((size_adjust, 5), dtype=np.int32)  # Specify dtype here\n",
    "        cycle[:, [0, 2, 4]] = zero_x\n",
    "        if trough[0] < peak[0]:\n",
    "            cycle[:, 1] = trough[:zero_x.shape[0]]\n",
    "            cycle[:, 3] = peak[:zero_x.shape[0]]\n",
    "        else:\n",
    "            cycle[:, 3] = trough[:zero_x.shape[0]]\n",
    "            cycle[:, 1] = peak[:zero_x.shape[0]]\n",
    "\n",
    "        broken_cycle = cycle[~np.all(np.diff(cycle, axis=1) > 0, axis=1)]\n",
    "        broken_cycle_mask = np.diff(broken_cycle, axis=1) > 0\n",
    "\n",
    "        adjust_condition = np.all(np.all(broken_cycle_mask[1:] == [True, False, False, True],\n",
    "                                         axis=0) == True)\n",
    "        adjust_loc = np.where(np.all(np.diff(cycle, axis=1) > 0, axis=1) == False)[0][1:-1]\n",
    "\n",
    "        fixed_cycle = broken_cycle[1:-1]\n",
    "        if adjust_condition:\n",
    "            fixed_cycle[:, 1] = cycle[adjust_loc - 1, 1]\n",
    "            fixed_cycle[:, 3] = cycle[adjust_loc + 1, 3]\n",
    "        else:\n",
    "            fixed_cycle[:, 3] = cycle[adjust_loc - 1, 3]\n",
    "            fixed_cycle[:, 1] = cycle[adjust_loc + 1, 1]\n",
    "\n",
    "        cycle = cycle[np.all(np.diff(cycle, axis=1) > 0, axis=1)]\n",
    "        cycle = np.vstack((cycle, fixed_cycle))\n",
    "        if trough[0] < peak[0]:\n",
    "            cycle = np.hstack((cycle[:-1, 1:-1], cycle[1:, :2]))\n",
    "        else:\n",
    "            cycle = np.hstack((cycle[:-1, 3].reshape((-1, 1)), cycle[1:, :-1]))\n",
    "\n",
    "        theta_peak_sig = np.append(theta_peak_sig, theta_sig[cycle[:, 2]])\n",
    "        cycles = np.vstack((cycles, cycle + start))\n",
    "\n",
    "    min_peak_amp = 2 * sub_theta_sig.std()\n",
    "    peak_mask = theta_peak_sig > min_peak_amp\n",
    "    upper_diff = np.floor(1000 / np.min(theta_range))\n",
    "    lower_diff = np.floor(1000 / np.max(theta_range))\n",
    "    diff_mask = np.logical_and(np.diff(cycles[:, [0, -1]], axis=1) * (1000 / sample_rate) > lower_diff,\n",
    "                               np.diff(cycles[:, [0, -1]], axis=1) * (1000 / sample_rate) <= upper_diff)\n",
    "\n",
    "    extrema_mask = np.logical_and(np.squeeze(diff_mask), peak_mask)\n",
    "\n",
    "    cycles = cycles[extrema_mask]\n",
    "\n",
    "    for j, rem in enumerate(rem_dict.values()):\n",
    "        rem['start-end'] = consecutive_rem_states[j].astype(np.int32)\n",
    "        rem['IMFs'] = rem_imf[j]\n",
    "        rem['IMF_Frequencies'] = rem_mask_freq[j]\n",
    "        rem['Instantaneous Phases'] = instantaneous_phase[j]\n",
    "        rem['Instantaneous Frequencies'] = instantaneous_freq[j]\n",
    "        rem['Instantaneous Amplitudes'] = instantaneous_amp[j]\n",
    "        cycles_mask = (cycles > consecutive_rem_states[j, 0]) & (cycles < consecutive_rem_states[j, 1])\n",
    "        cycles_mask = np.all(cycles_mask == True, axis=1)\n",
    "        rem_cycles = cycles[cycles_mask]\n",
    "        rem['Cycles'] = rem_cycles.astype(np.int32)\n",
    "    return rem_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bin_tf_to_fpp(x, power, bin_count):\n",
    "    if x.ndim == 1:  # Handle the case when x is of size (2)\n",
    "        bin_ranges = np.arange(x[0], x[1], 1)\n",
    "        fpp = binned_statistic(bin_ranges, power[:, x[0]:x[1]], 'mean', bins=bin_count)[0]\n",
    "        fpp = np.expand_dims(fpp, axis=0)  # Add an extra dimension to match the desired output shape\n",
    "    elif x.ndim == 2:  # Handle the case when x is of size (n, 2)\n",
    "        fpp = []\n",
    "        for i in range(x.shape[0]):\n",
    "            bin_ranges = np.arange(x[i, 0], x[i, 1], 1)\n",
    "            fpp_row = binned_statistic(bin_ranges, power[:, x[i, 0]:x[i, 1]], 'mean', bins=bin_count)[0]\n",
    "            fpp.append(fpp_row)\n",
    "        fpp = np.array(fpp)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid size for x\")\n",
    "\n",
    "    return fpp\n",
    "\n",
    "\n",
    "def calculate_cog(frequencies, angles, amplitudes, ratio):\n",
    "    angles = np.deg2rad(angles)\n",
    "    cog = np.empty((0, 2))\n",
    "    if amplitudes.ndim == 2:\n",
    "        numerator = np.sum(frequencies * np.sum(amplitudes, axis=1))\n",
    "        denominator = np.sum(amplitudes)\n",
    "        cog_f = numerator / denominator\n",
    "        floor = np.floor(cog_f).astype(int) - frequencies[0]\n",
    "        ceil = np.ceil(cog_f).astype(int) - frequencies[0]\n",
    "        new_fpp = np.where(amplitudes >= np.max(amplitudes[[floor, ceil], :]) * ratio, amplitudes, 0)\n",
    "        cog_ph = np.rad2deg(pg.circ_mean(angles, w=np.sum(new_fpp, axis=0)))\n",
    "        cog = np.array([cog_f, cog_ph])\n",
    "    elif amplitudes.ndim == 3:\n",
    "        indices_to_subset = np.empty((amplitudes.shape[0], 2)).astype(int)\n",
    "        cog = np.empty((amplitudes.shape[0], 2))\n",
    "        numerator = np.sum(frequencies * np.sum(amplitudes, axis=2), axis=1)\n",
    "        denominator = np.sum(amplitudes, axis=(1, 2))\n",
    "        cog_f = (numerator / denominator)\n",
    "        vectorized_floor = np.vectorize(np.floor)\n",
    "        vectorized_ceil = np.vectorize(np.ceil)\n",
    "        indices_to_subset[:, 0] = vectorized_floor(cog_f) - frequencies[0]\n",
    "        indices_to_subset[:, 1] = vectorized_ceil(cog_f) - frequencies[0]\n",
    "        max_amps = np.max(amplitudes[np.arange(amplitudes.shape[0])[:, np.newaxis], indices_to_subset, :], axis=(1, 2))\n",
    "        print(max_amps.shape)\n",
    "        for i, max_amp in enumerate(max_amps):\n",
    "            new_fpp = np.where(amplitudes[i] >= max_amp * ratio, amplitudes[i], 0)\n",
    "            cog[i, 1] = np.rad2deg(pg.circ_mean(angles, w=np.sum(new_fpp, axis=0)))\n",
    "        cog[:, 0] = cog_f\n",
    "    return cog\n",
    "\n",
    "\n",
    "def boxcar_smooth(x, boxcar_window):\n",
    "    if x.ndim == 1:\n",
    "        if boxcar_window % 2 == 0:\n",
    "            boxcar_window += 1\n",
    "        window = np.ones((1, boxcar_window)) / boxcar_window\n",
    "        x_spectrum = np.convolve(x, window, mode='same')\n",
    "    else:\n",
    "        bool_window = np.where(~boxcar_window % 2 == 0, boxcar_window, boxcar_window + 1)\n",
    "        window_t = np.ones((1, bool_window[0])) / bool_window[0]\n",
    "        window_f = np.ones((1, bool_window[1])) / bool_window[1]\n",
    "        x_spectrum_t = convolve2d(x, window_t, mode='same')\n",
    "        x_spectrum = convolve2d(x_spectrum_t, window_f.T, mode='same')\n",
    "\n",
    "    return x_spectrum\n",
    "\n",
    "\n",
    "# def peak_cog(frequencies, angles, amplitudes, ratio):\n",
    "#     def nearest_peaks(frequency, angle, amplitude, ratio):\n",
    "#         peak_indices = peak_local_max(amplitude, min_distance=1, threshold_abs=0)\n",
    "#         cog_f = calculate_cog(frequency, angle, amplitude, ratio)\n",
    "\n",
    "#         if peak_indices.shape[0] == 0:\n",
    "#             cog_peak = cog_f\n",
    "#         else:\n",
    "#             cog_fx = np.array([cog_f[0], cog_f[0] * np.cos(np.deg2rad(cog_f[1] - angle[0])),\n",
    "#                                cog_f[0] * np.sin(np.deg2rad(cog_f[1] - angle[0]))])\n",
    "#             peak_loc = peak_loc = np.empty((peak_indices.shape[0], 4))\n",
    "#             peak_loc[:, [0, 1]] = np.array([frequency[peak_indices.T[0]], angle[peak_indices.T[1]]]).T\n",
    "#             peak_loc[:, 2] = peak_loc[:, 0] * np.cos(np.deg2rad(peak_loc[:, 1] - angle[0]))\n",
    "#             peak_loc[:, 3] = peak_loc[:, 0] * np.sin(np.deg2rad(peak_loc[:, 1] - angle[0]))\n",
    "#             peak_loc = peak_loc[:, [0, 2, 3]]\n",
    "#             distances = np.abs(peak_loc - cog_fx)\n",
    "\n",
    "#             cog_pos = peak_indices[np.argmin(np.linalg.norm(distances, axis=1))]\n",
    "\n",
    "#             cog_peak = np.array([frequency[cog_pos[0]], angle[cog_pos[1]]])\n",
    "\n",
    "#         return cog_peak\n",
    "\n",
    "#     if amplitudes.ndim == 2:\n",
    "#         cog = nearest_peaks(frequencies, angles, amplitudes, ratio)\n",
    "#     elif amplitudes.ndim == 3:\n",
    "#         cog = np.empty((amplitudes.shape[0], 2))\n",
    "#         for i, fpp in enumerate(amplitudes):\n",
    "#             cog[i] = nearest_peaks(frequencies, angles, fpp, ratio)\n",
    "#     return cog\n",
    "\n",
    "\n",
    "# def max_peaks(amplitudes):\n",
    "#     new_fpp = np.zeros(amplitudes.shape)\n",
    "#     if amplitudes.ndim == 2:\n",
    "#         peak_indices = peak_local_max(amplitudes, min_distance=1, threshold_abs=0)\n",
    "#         if peak_indices.shape[0] == 0:\n",
    "#             new_fpp = np.where(amplitudes > 0, amplitudes, 0)\n",
    "#         else:\n",
    "#             new_fpp[peak_indices.T[0], peak_indices.T[1]] = amplitudes[peak_indices.T[0], peak_indices.T[1]]\n",
    "#     elif amplitudes.ndim == 3:\n",
    "#         for i, fpp in enumerate(amplitudes):\n",
    "#             peak_indices = peak_local_max(fpp, min_distance=1, threshold_abs=0)\n",
    "#             if peak_indices.shape[0] == 0:\n",
    "#                 new_fpp[i] = np.where(fpp > 0, fpp, 0)\n",
    "#             else:\n",
    "#                 new_fpp[i, peak_indices.T[0], peak_indices.T[1]] = fpp[peak_indices.T[0], peak_indices.T[1]]\n",
    "#     return new_fpp\n",
    "\n",
    "\n",
    "# def boundary_peaks(amplitudes):\n",
    "#     adjusted_fpp = np.zeros(amplitudes.shape)\n",
    "#     if amplitudes.ndim == 2:\n",
    "#         peak_indices = peak_local_max(amplitudes, min_distance=1, threshold_abs=0)\n",
    "#         if peak_indices.shape[0] == 0:\n",
    "#             adjusted_fpp = np.where(amplitudes > 0, amplitudes, 0)\n",
    "#         else:\n",
    "#             new_fpp = amplitudes[peak_indices.T[0], peak_indices.T[1]]\n",
    "#             maximum = np.max(new_fpp)\n",
    "#             minimum = np.min(new_fpp)\n",
    "#             adjusted_fpp = np.where((amplitudes <= maximum) & (amplitudes >= 0.95*minimum), amplitudes, 0)\n",
    "#     elif amplitudes.ndim == 3:\n",
    "#         for i, fpp in enumerate(amplitudes):\n",
    "#             peak_indices = peak_local_max(fpp, min_distance=1, threshold_abs=0)\n",
    "#             print(peak_indices.shape)\n",
    "#             if peak_indices.shape[0] == 0:\n",
    "#                 adjusted_fpp[i] = np.where(fpp > 0, fpp, 0)\n",
    "#             else:\n",
    "#                 maximum = np.max(fpp[peak_indices.T[0], peak_indices.T[1]])\n",
    "#                 minimum = np.min(fpp[peak_indices.T[0], peak_indices.T[1]])\n",
    "#                 adjusted_fpp[i] = np.where((fpp <= maximum) & (fpp >= 0.95*minimum), fpp, 0)\n",
    "#     return adjusted_fpp\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def rem_fpp_gen(rem_dict, x, sample_rate, frequencies, angles, ratio, boxcar_window=None, norm='', fpp_method='',\n",
    "                cog_method=''):\n",
    "    x = np.squeeze(x)\n",
    "    cycles_dict = rem_dict\n",
    "    rem_dict = {}\n",
    "    sub_dict = rem_dict\n",
    "    for key, value in cycles_dict.items():\n",
    "        print(key)\n",
    "        if 'Cycles' in value.keys():\n",
    "            sub_dict.setdefault(key, {})\n",
    "            t = value['start-end'].astype(np.int32)\n",
    "            print(t, t[0], t[1])\n",
    "            sig = x[t[0]:t[1]]\n",
    "            print(sig.shape)\n",
    "            power = morlet_wt(sig, sample_rate, frequencies, mode='power').astype(np.float32)\n",
    "            cycles = (value['Cycles'][:, [0, -1]] - t[0]).astype(np.int32)\n",
    "            # if boxcar_window is not None:\n",
    "            #     power = boxcar_smooth(power, boxcar_window)\n",
    "            # if norm == 'simple_x':\n",
    "            #     power = power / np.sum(power, axis=0)\n",
    "            # elif norm == 'simple_y':\n",
    "            #     power = power / np.sum(power, axis=1)[:, np.newaxis]\n",
    "            # elif norm == 'zscore_y':\n",
    "            #     power = zscore(power, axis=0)\n",
    "            # elif norm == 'zscore_x':\n",
    "            #     power = zscore(power, axis=1)\n",
    "            fpp_plots = bin_tf_to_fpp(cycles, power, 19).astype(np.float32)\n",
    "            sub_dict[key]['FPP_cycles'] = fpp_plots\n",
    "            # if fpp_method == 'max_peaks':\n",
    "            #     fpp_plots = max_peaks(fpp_plots)\n",
    "            #     print(fpp_plots.shape)\n",
    "            # elif fpp_method == 'boundary_peaks':\n",
    "            #     fpp_plots = boundary_peaks(fpp_plots)\n",
    "            # if cog_method == 'nearest':\n",
    "            #     cog = peak_cog(frequencies, angles, fpp_plots, ratio).astype(np.float32)\n",
    "            # else:\n",
    "            #     cog = calculate_cog(frequencies, angles, fpp_plots, ratio).astype(np.float32)\n",
    "            # sub_dict[key]['CoG'] = cog\n",
    "        else:\n",
    "            continue\n",
    "    return rem_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ae549c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10802)\n",
      "Key: REM 1, Value Type: <class 'dict'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid data type in rem_dict for key 'REM 1': <class 'dict'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 135\u001b[0m\n\u001b[0;32m    133\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Create a list to collect processed data\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subfolder \u001b[38;5;129;01min\u001b[39;00m subfolders:\n\u001b[1;32m--> 135\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_subfolder_with_timing\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call the method and collect the dictionaries\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     processed_data\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn [5], line 114\u001b[0m, in \u001b[0;36mDataProcessor.process_subfolder_with_timing\u001b[1;34m(self, subfolder)\u001b[0m\n\u001b[0;32m    112\u001b[0m lfp_data, states_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_data(subfolder)\n\u001b[0;32m    113\u001b[0m rem_dict, rem_tf_power_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_data(lfp_data, states_data)  \u001b[38;5;66;03m# Process and get the rem_dict\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrem_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrem_tf_power_dict\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Save the rem_dict\u001b[39;00m\n\u001b[0;32m    115\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Stop measuring time\u001b[39;00m\n\u001b[0;32m    116\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time  \u001b[38;5;66;03m# Calculate elapsed time\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [5], line 82\u001b[0m, in \u001b[0;36mDataProcessor.save_data\u001b[1;34m(self, subfolder, rem_dict, rem_tf_power_dict)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Value Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Add this line for debugging\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m---> 82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid data type in rem_dict for key \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Validate data types in rem_tf_power_dict\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m rem_tf_power_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid data type in rem_dict for key 'REM 1': <class 'dict'>"
     ]
    }
   ],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, data_dir, output_dir):\n",
    "        # Initialize the data and output directories.\n",
    "        self.data_dir = data_dir  # Set the input data directory.\n",
    "        self.output_dir = output_dir  # Set the output data directory.\n",
    "\n",
    "    def load_data(self, subfolder):\n",
    "        # Generate file paths for LFP and states data using glob.\n",
    "        # Find the file that matches the pattern '*HPC*' in the specified subfolder.\n",
    "        lfp_file = glob.glob(os.path.join(self.data_dir, subfolder, '*HPC*'))[0]\n",
    "        # Find the file that matches the pattern '*states*' in the specified subfolder.\n",
    "        states_file = glob.glob(os.path.join(self.data_dir, subfolder, '*states*'))[0]\n",
    "\n",
    "        # Load LFP and states data using scipy's loadmat function.\n",
    "        lfp_data = sio.loadmat(lfp_file)['HPC']  # Load LFP data from the MATLAB file.\n",
    "        states_data = sio.loadmat(states_file)['states']  # Load states data.\n",
    "        print(states_data.shape)\n",
    "        return lfp_data, states_data \n",
    "       \n",
    "\n",
    "    def process_data(self, lfp_data, states_data):\n",
    "        # Add your data processing pipeline here.\n",
    "        # For example, you can apply signal processing or any other data transformations.\n",
    "        # For now, we're just passing through the data as-is.\n",
    "        rem_dict = get_cycles_data(lfp_data, states_data, 2500, (5, 12))\n",
    "    \n",
    "        # MW\n",
    "        rem_periods = get_rem_states(states_data, 2500).astype(int)\n",
    "    \n",
    "        rem_signals=[]\n",
    "        for rem in rem_periods:\n",
    "            signal = lfp_data[rem[0]:rem[1]]\n",
    "            rem_signals.append(np.squeeze(signal))\n",
    "    \n",
    "        frequencies = np.arange (20, 140, 1)\n",
    "        angles = np.linspace(-180, 180, 19)\n",
    "        rem_tf_power_dict = {}  # Initialize a dictionary to store power for all REM periods\n",
    "\n",
    "        for i, sig in enumerate(rem_signals):\n",
    "            power = morlet_wt(sig, 2500, frequencies, mode='power')\n",
    "    \n",
    "            # Calculate summed power values for the current REM period\n",
    "            summed_power_values = np.sum(power, axis=1)\n",
    "            \n",
    "            # Convert power and summed_power_values to suitable data types (e.g., float32)\n",
    "            power = np.array(power, dtype=np.float32)\n",
    "            summed_power_values = np.array(summed_power_values, dtype=np.float32)\n",
    "    \n",
    "            # Store 'power' and 'summed_power_values' for the current REM period in a dictionary\n",
    "            rem_tf_power_dict[f'REM_period_{i + 1}'] = {\n",
    "                'tf_power': power,\n",
    "                'summed_power': summed_power_values\n",
    "            }\n",
    "        for key, value in rem_dict.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                rem_dict[key] = np.float32(value)  # Convert numerical values to np.float32\n",
    "                \n",
    "        return rem_dict, rem_tf_power_dict\n",
    "\n",
    "            # Now, rem_tf_power_dict contains both time-frequency power and summed power values for each REM period\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "    def save_data(self, subfolder, rem_dict, rem_tf_power_dict):\n",
    "        # Create an output subfolder if it doesn't exist.\n",
    "        output_subfolder = os.path.join(self.output_dir, subfolder)\n",
    "        os.makedirs(output_subfolder, exist_ok=True)\n",
    "        \n",
    "        # Define the output file paths based on the subfolder name.\n",
    "        rem_dict_filename = f\"{subfolder}_REM_dict.h5\"\n",
    "        rem_dict_file = os.path.join(output_subfolder, rem_dict_filename)\n",
    "        \n",
    "        rem_tf_power_dict_filename = f\"{subfolder}_REM_tf_power_dict.h5\"\n",
    "        rem_tf_power_dict_file = os.path.join(output_subfolder, rem_tf_power_dict_filename)\n",
    "        \n",
    "        # Validate data types in rem_dict\n",
    "        for key, value in rem_dict.items():\n",
    "            print(f\"Key: {key}, Value Type: {type(value)}\")  # Add this line for debugging\n",
    "            if not isinstance(value, (int, float, np.ndarray)):\n",
    "                raise ValueError(f\"Invalid data type in rem_dict for key '{key}': {type(value)}\")\n",
    "\n",
    "        # Validate data types in rem_tf_power_dict\n",
    "        for key, value in rem_tf_power_dict.items():\n",
    "            if not isinstance(value['tf_power'], np.ndarray) or not isinstance(value['summed_power'], np.ndarray):\n",
    "                raise ValueError(f\"Invalid data type in rem_tf_power_dict for key '{key}'\")\n",
    "\n",
    "        # Save the rem_dict dictionary as an HDF5 file.\n",
    "        with h5py.File(rem_dict_file, 'w') as hdf_file:\n",
    "            # Create a group to store the rem_dict data\n",
    "            rem_dict_group = hdf_file.create_group('REM_dict_group')\n",
    "\n",
    "            # Save each key-value pair from rem_dict into the HDF5 group\n",
    "            for key, value in rem_dict.items():\n",
    "                # Use key as the dataset name and store the value\n",
    "                rem_dict_group[key] = value\n",
    "\n",
    "        # Save the rem_tf_power_dict dictionary as an HDF5 file.\n",
    "        with h5py.File(rem_tf_power_dict_file, 'w') as hdf_file:\n",
    "            # Create a group to store the rem_tf_power_dict data\n",
    "            rem_tf_power_dict_group = hdf_file.create_group('REM_tf_power_dict_group')\n",
    "\n",
    "            # Save each key-value pair from rem_tf_power_dict into the HDF5 group\n",
    "            for key, value in rem_tf_power_dict.items():\n",
    "                # Use key as the dataset name and store the value\n",
    "                rem_tf_power_dict_group[key] = value\n",
    "\n",
    "      \n",
    "    def process_subfolder_with_timing(self, subfolder):\n",
    "        start_time = time.time()  # Start measuring time\n",
    "        lfp_data, states_data = self.load_data(subfolder)\n",
    "        rem_dict, rem_tf_power_dict = self.process_data(lfp_data, states_data)  # Process and get the rem_dict\n",
    "        self.save_data(subfolder, rem_dict, rem_tf_power_dict)  # Save the rem_dict\n",
    "        end_time = time.time()  # Stop measuring time\n",
    "        elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "        print(elapsed_time)  # Print the elapsed time in seconds\n",
    "        # Return the dictionaries\n",
    "        return rem_dict, rem_tf_power_dict\n",
    "\n",
    "\n",
    "\n",
    "# Specify the input data directory and output directory.\n",
    "data_dir = \"E:/Donders/Data\"  # Replace with your actual data directory path.\n",
    "output_dir = \"E:/Donders/Output\"  # Replace with your desired output directory path.\n",
    "\n",
    "# Create a DataProcessor object.\n",
    "processor = DataProcessor(data_dir, output_dir)\n",
    "\n",
    "# Process all data in the specified directories using parallel processing.\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    subfolders = [subfolder for subfolder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, subfolder))]\n",
    "    processed_data = []  # Create a list to collect processed data\n",
    "    for subfolder in subfolders:\n",
    "        result = processor.process_subfolder_with_timing(subfolder)  # Call the method and collect the dictionaries\n",
    "        processed_data.append(result)  # Append the dictionaries to the list\n",
    "\n",
    "# Now, 'processed_data' contains the dictionaries for each subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d69c858",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_rem_states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rem_periods\u001b[38;5;241m=\u001b[39m \u001b[43mget_rem_states\u001b[49m(states, \u001b[38;5;241m2500\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(rem_periods)\n\u001b[0;32m      3\u001b[0m rem_signals\u001b[38;5;241m=\u001b[39m[]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_rem_states' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcd6d402",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'elapsed_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(\u001b[43melapsed_time\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'elapsed_time' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a0ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
